# Global Detection and Performance Settings
# This file contains cross-cutting configuration that applies to all models

# ============================================================================
# DETECTION SETTINGS
# ============================================================================
[detection]
# Confidence threshold for entity detection (0.0 to 1.0)
default_threshold = 0.7

# Enable multi-model aggregation (true/false)
multi_detector_enabled = false

# Enable LLM-based detection (true/false)
# When true, enables ML models (GLiNER, Piiranha, etc.) for PII detection
# When false, all LLM models are disabled regardless of their individual config
# Note: At least one detection method (LLM, Regex, or Presidio) must be enabled
llm_detection_enabled = true

# Enable regex-based detection (true/false)
# When true, adds RegexDetector to CompositePIIDetector
# When false, regex detection is disabled
regex_detection_enabled = false

# Enable Presidio-based detection (true/false)
# When true, adds PresidioDetector to CompositePIIDetector
# Presidio provides production-ready, rule-based PII detection by Microsoft
# When false, Presidio detection is disabled
presidio_detection_enabled = true

# Log detailed provenance information about which model detected each entity
log_provenance = true

# Log throughput metrics (chars/second) for performance monitoring
log_throughput = true

# Token overlap for chunk splitting (prevents boundary truncation)
# Recommended 10-20% of max_length for optimal entity detection at boundaries
# For GLiNER (720 tokens): 100 tokens overlap = 13.9%
stride_tokens = 100

# Character threshold to trigger chunked processing
long_text_threshold = 10000

# ============================================================================
# AGGREGATION SETTINGS
# Settings for combining results when using multiple models
# ============================================================================
[aggregation]
# Deduplication method: "max_score", "average_score", "consensus"
deduplication_method = "max_score"

# Overlap resolution strategy: "prefer_longer", "prefer_confident", "prefer_priority"
overlap_resolution = "prefer_longer"

# Minimum number of models that must detect an entity (comment out = disabled)
# min_consensus = 2

# ============================================================================
# PARALLEL PROCESSING SETTINGS
# Settings for parallel text processing within a single model
# ============================================================================
[parallel_processing]
# Enable parallel processing of multiple texts (ThreadPoolExecutor)
# When true, multiple texts are processed in parallel by the same model
# Performance impact: ~49% faster with 5 workers (based on benchmark tests)
# Note: This is NOT batch processing (which GLiNER doesn't support)
# This uses ThreadPoolExecutor to process multiple texts concurrently
enabled = true

# Number of worker threads for parallel text processing
# Recommended values based on CPU cores:
# - 3 workers: Good balance for 4-core CPUs (~43% gain)
# - 5 workers: Optimal for 6-8 core CPUs (~49% gain)
# - Set to 1 to disable parallelization (sequential processing)
max_workers = 10

# Minimum number of texts to trigger parallel processing
# If batch has fewer texts than this threshold, process sequentially
# This avoids overhead for small batches
min_texts_for_parallel = 3

# ============================================================================
# PERFORMANCE SETTINGS  
# Settings for multi-model execution
# ============================================================================
[performance]
# Enable parallel execution of MULTIPLE models (not the same as parallel_processing above)
# This allows running multiple different models simultaneously
parallel_execution = true

# Maximum number of worker threads for multi-model parallel execution
# (comment out = auto-detect based on CPU cores)
# max_workers = 4

# Timeout per model in seconds (increased to 180s to handle complex pages)
model_timeout = 180
