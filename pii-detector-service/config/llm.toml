# Configuration for LLM (Language Model) Detection Settings
# This file contains settings for multiple PII detection models

# Global detection settings
[detection]
# Confidence threshold for entity detection (0.0 to 1.0)
default_threshold = 0.5

# Enable multi-model aggregation (true/false)
multi_detector_enabled = true

# Log detailed provenance information about which model detected each entity
log_provenance = true

# Batch size for processing multiple texts
batch_size = 4

# Token overlap for chunk splitting (prevents boundary truncation)
# Recommended 10-20% of max_length for optimal entity detection at boundaries
# For GLiNER (720 tokens): 100 tokens overlap = 13.9%
stride_tokens = 100

# Character threshold to trigger chunked processing
long_text_threshold = 10000

# Aggregation settings when using multiple models
[aggregation]
# Deduplication method: "max_score", "average_score", "consensus"
deduplication_method = "max_score"

# Overlap resolution strategy: "prefer_longer", "prefer_confident", "prefer_priority"
overlap_resolution = "prefer_longer"

# Minimum number of models that must detect an entity (comment out = disabled)
# min_consensus = 2

# Performance settings
[performance]
# Enable parallel execution of models
parallel_execution = true

# Maximum number of worker threads (comment out = auto-detect)
# max_workers = 4

# Timeout per model in seconds
model_timeout = 60

# Model 1: Piiranha-v1 (Primary model for PII detection)
[models.piiranha-v1]
# Enable or disable this model
enabled = false

# Hugging Face model identifier
model_id = "iiiorg/piiranha-v1-detect-personal-information"

# Human-readable description
description = "Primary model for multilingual PII detection"

# Priority (1 = highest priority, used for conflict resolution)
priority = 1

# Device allocation: "cpu", "cuda", or "mps"
device = "cpu"

# Maximum token length for model context window
max_length = 256

# Model-specific confidence threshold (comment out = use default_threshold)
# threshold = 0.5

# Download settings for this model
[models.piiranha-v1.download]
# Uncomment to specify custom cache directory
# cache_dir = "/path/to/cache"
force_download = false
resume_download = true

# PII type mapping (rename detected types if needed)
[models.piiranha-v1.pii_type_mapping]
# Example: EMAILADDRESS = "EMAIL"

# Model 2: Multilingual PII NER (Secondary model for emails and multilingual PII)
[models.multilang-pii-ner]
# Enable or disable this model
enabled = false

# Hugging Face model identifier
model_id = "Ar86Bat/multilang-pii-ner"

# Human-readable description
description = "Complementary model for emails and multilingual PII detection"

# Priority (2 = secondary priority)
priority = 2

# Device allocation: "cpu", "cuda", or "mps"
device = "cpu"

# Maximum token length for model context window
max_length = 256

# Model-specific confidence threshold (higher threshold for this model)
threshold = 0.6

# Download settings for this model
[models.multilang-pii-ner.download]
# Uncomment to specify custom cache directory
# cache_dir = "/path/to/cache"
force_download = false
resume_download = true

# PII type mapping (rename detected types if needed)
[models.multilang-pii-ner.pii_type_mapping]
# Add any specific type mappings here if needed

# Model 3: GLiNER PII Large v1.0 (Advanced PII detection with 17 types)
# âœ… Fully integrated with custom GLiNERDetector adapter
# Uses GLiNER.from_pretrained() and predict_entities() API with natural language labels
# Automatically detected and loaded by MultiModelPIIDetector when enabled
[models.gliner-pii]
# Enable or disable this model
enabled = true

# Hugging Face model identifier
model_id = "knowledgator/gliner-pii-large-v1.0"

# Human-readable description
description = "GLiNER PII large v1.0 - Advanced multilingual PII detection supporting 17 entity types"

# Priority (3 = tertiary priority)
priority = 3

# Device allocation: "cpu", "cuda", or "mps"
device = "cpu"

# Maximum token length for model context window (GLiNER actual limit: 768 tokens)
# Using 720 tokens to leave margin for special tokens, with 100 tokens overlap (13.9%)
max_length = 720

# Model-specific confidence threshold (optimized for GLiNER)
threshold = 0.3

# Download settings for this model
[models.gliner-pii.download]
# Uncomment to specify custom cache directory
# cache_dir = "/path/to/cache"
force_download = false
resume_download = true

# Custom filenames for GLiNER model (uses gliner_config.json instead of config.json)
[models.gliner-pii.download.custom_filenames]
"config.json" = "gliner_config.json"

# PII type mapping - Maps GLiNER labels to piiranha-v1 standard types
# GLiNER uses natural language labels, mapped here to normalized PII types
[models.gliner-pii.pii_type_mapping]
"account number" = "ACCOUNTNUM"
"building number" = "BUILDINGNUM"
"city" = "CITY"
"credit card number" = "CREDITCARDNUMBER"
"date of birth" = "DATEOFBIRTH"
"driver license number" = "DRIVERLICENSENUM"
"email" = "EMAIL"
"first name" = "GIVENNAME"
"ID card number" = "IDCARDNUM"
"password" = "PASSWORD"
"social security number" = "SOCIALNUM"
"street" = "STREET"
"last name" = "SURNAME"
"tax number" = "TAXNUM"
"phone number" = "TELEPHONENUM"
"username" = "USERNAME"
"zip code" = "ZIPCODE"
